CLIP Fine-Tuner FastAPI
This project provides a FastAPI application to serve a fine-tuned CLIP model for image classification. Users can upload an image and specify a model name to get predictions based on predefined subcategories.

Prerequisites
Python 3.8 or higher
FastAPI
torch (PyTorch)
clip (CLIP)
PIL (Pillow)
requests
You can install the required packages using pip:
pip install fastapi torch pillow requests


File Structure
app.py: FastAPI application for serving the fine-tuned CLIP model.
predict.py: Command-line utility to interact with the FastAPI endpoint.
Setup
Model Files

Ensure that you have your fine-tuned CLIP model files in the models/clip/ directory. The model file paths should be specified in the model_info dictionary within app.py.


Run the FastAPI Server
Start the FastAPI server by running:

uvicorn app:app --reload
The server will be available at http://127.0.0.1:8000.


Usage
API Endpoint
The FastAPI application exposes the /predict/ endpoint for image classification. To get a prediction:

Method: POST
URL: http://127.0.0.1:8000/predict/
Parameters:
file: The image file to be classified.
model_name: The name of the model to be used for classification. (Must match one of the keys in model_info)

Example Request:
You can test the API using the provided predict.py script. Run the script with the following command:

python predict.py <image_path> <model_name>


Replace <image_path> with the path to your image file and <model_name> with one of the predefined model names.




Example:
python predict.py my_image.jpg hineng

The script will print the JSON response from the server, which includes the predicted class.




Error Handling
If an invalid model name is provided or if an error occurs during processing, the API will return an error message.

License
This project is licensed under the MIT License - see the LICENSE file for details.